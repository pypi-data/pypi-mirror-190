
<!DOCTYPE html>

<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>如何使用 TVM Pass Infra &#8212; TVM  文档</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../../_static/translations.js"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <link rel="icon" href="../../../_static/tvm-logo-square.png"/>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="如何使用 TVM Pass Instrument" href="use_pass_instrument.html" />
    <link rel="prev" title="编写定制 Pass" href="low_level_custom_pass.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh-CN">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      <img src="../../../_static/../../../_static/tvm-logo-small.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">TVM  文档</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   TVM Documentation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../start.html">
   Getting Started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../install/index.html">
     Installing TVM
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../install/from_source.html">
       Install from Source
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
      <label for="toctree-checkbox-3">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../install/nnpack.html">
         NNPACK Contrib Installation
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../install/docker.html">
       Docker Images
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../install/nnpack.html">
       NNPACK Contrib Installation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../contribute/index.html">
     Contributor Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/community.html">
       TVM Community Guidelines
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/pull_request.html">
       Submit a Pull Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/code_review.html">
       Code Reviews
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/committer_guide.html">
       Committer Guide
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/document.html">
       Documentation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/code_guide.html">
       Code Guide and Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/git_howto.html">
       Git Usage Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/ci.html">
       Using TVM’s CI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/release_process.html">
       Release Process
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/error_handling.html">
       Error Handling Guide
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../../user-guide.html">
   用户手册
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorial/index.html">
     用户指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/introduction.html">
       TVM 和模型优化的概述
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/tvmc_command_line_driver.html">
       用 TVMC 编译和优化模型
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/tvmc_python.html">
       开始使用 TVMC Python：TVM 的高级 API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/autotvm_relay_x86.html">
       用 Python 接口编译和优化模型（AutoTVM）
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/tensor_expr_get_started.html">
       使用张量表达式处理算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/autotvm_matmul_x86.html">
       用调度模板和 AutoTVM 优化算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/auto_scheduler_matmul_x86.html">
       使用自动调度优化运算
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/tensor_ir_blitz_course.html">
       TensorIR 的突击课程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/cross_compilation_and_rpc.html">
       交叉编译和RPC
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/relay_quick_start.html">
       编译深度学习模型的快速入门教程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/intro_topi.html">
       TOPI 简介
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/uma.html">
       通过 UMA 使您的硬件加速器 TVM-ready
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../index.html">
     How To 指南
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../compile_models/index.html">
       编译深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_pytorch.html">
         编译 PyTorch 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_tensorflow.html">
         Compile Tensorflow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_mxnet.html">
         编译 MXNet 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_onnx.html">
         Compile ONNX Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_keras.html">
         Compile Keras Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_tflite.html">
         Compile TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_coreml.html">
         Compile CoreML Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_darknet.html">
         Compile YOLO-V2 and YOLO-V3 in DarkNet Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_caffe2.html">
         Compile Caffe2 Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_oneflow.html">
         Compile OneFlow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../compile_models/from_paddle.html">
         Compile PaddlePaddle Models
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../deploy/index.html">
       部署模型并集成到 TVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/cpp_deploy.html">
         使用 C++ API 部署 TVM Module
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/android.html">
         Deploy to Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/adreno.html">
         Deploy to Adreno GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/integrate.html">
         集成 TVM 到你的项目
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/hls.html">
         HLS Backend Example
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/arm_compute_lib.html">
         集成 Relay Arm
         <sup>
          ®
         </sup>
         计算库
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/tensorrt.html">
         Relay TensorRT Integration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/vitis_ai.html">
         Vitis AI Integration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy/bnns.html">
         Relay BNNS Integration
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../deploy_models/index.html">
       部署深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy_models/deploy_model_on_android.html">
         Deploy the Pretrained Model on Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy_models/deploy_model_on_rasp.html">
         Deploy the Pretrained Model on Raspberry Pi
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy_models/deploy_object_detection_pytorch.html">
         编译 PyTorch 目标检测模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy_models/deploy_prequantized.html">
         使用 TVM 部署框架预量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy_models/deploy_prequantized_tflite.html">
         Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy_models/deploy_quantized.html">
         在 CUDA 上部署已量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy_models/deploy_sparse.html">
         Deploy a Hugging Face Pruned Model on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../deploy_models/deploy_ssd_gluoncv.html">
         部署 Single Shot Multibox Detector(SSD) 模型
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../work_with_relay/index.html">
       使用 Relay
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
      <label for="toctree-checkbox-11">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_relay/build_gcn.html">
         构建图卷积网络
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_relay/using_external_lib.html">
         在 Relay 中使用外部库
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_relay/using_pipeline_executor.html">
         在 Relay 中使用管道执行器
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_relay/using_relay_viz.html">
         使用 Relay Visualizer 可视化 Relay
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../work_with_schedules/index.html">
       使用 Tensor Expression 和 Schedules
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_schedules/schedule_primitives.html">
         TVM 中的调度原语
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_schedules/reduction.html">
         Reduction
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_schedules/intrin_math.html">
         Intrinsics and Math Functions
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_schedules/scan.html">
         Scan and Recurrent Kernel
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_schedules/extern_op.html">
         外部张量函数
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_schedules/tensorize.html">
         Use Tensorize to Leverage Hardware Intrinsics
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_schedules/tuple_inputs.html">
         Compute and Reduce with Tuple Inputs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_schedules/tedd.html">
         使用 TEDD 进行可视化
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../optimize_operators/index.html">
       优化张量算子
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
      <label for="toctree-checkbox-13">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../optimize_operators/opt_gemm.html">
         How to optimize GEMM on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../optimize_operators/opt_conv_cuda.html">
         How to optimize convolution on GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../optimize_operators/opt_conv_tensorcore.html">
         How to optimize convolution using TensorCores
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../tune_with_autotvm/index.html">
       Auto-Tune with Templates and AutoTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autotvm/tune_conv2d_cuda.html">
         Tuning High Performance Convolution on NVIDIA GPUs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autotvm/tune_relay_cuda.html">
         Auto-tuning a Convolutional Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autotvm/tune_relay_x86.html">
         Auto-tuning a Convolutional Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autotvm/tune_relay_arm.html">
         Auto-tuning a Convolutional Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autotvm/tune_relay_mobile_gpu.html">
         Auto-tuning a Convolutional Network for Mobile GPU
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../tune_with_autoscheduler/index.html">
       使用自动调度器进行无模板调度
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autoscheduler/tune_conv2d_layer_cuda.html">
         Auto-scheduling a Convolution Layer for GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autoscheduler/tune_network_x86.html">
         Auto-scheduling a Neural Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autoscheduler/tune_network_cuda.html">
         Auto-scheduling a Neural Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autoscheduler/tune_network_arm.html">
         Auto-scheduling a Neural Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autoscheduler/tune_network_mali.html">
         Auto-scheduling a Neural Network for mali GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tune_with_autoscheduler/tune_sparse_x86.html">
         Auto-scheduling Sparse Matrix Multiplication on CPU with Custom Sketch Rule
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../work_with_microtvm/index.html">
       使用 microTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_microtvm/micro_aot.html">
         microTVM Host-Driven AoT
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_microtvm/micro_autotune.html">
         使用 microTVM Autotuning
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_microtvm/micro_ethosu.html">
         在 bare metal Arm® Cortex®-M55 CPU 和 Ethos™-U55 NPU 上运行 TVM
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_microtvm/micro_reference_vm.html">
         microTVM 参考虚拟机
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_microtvm/micro_tflite.html">
         microTVM with TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_microtvm/micro_train.html">
         Training Vision Models for microTVM on Arduino
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../work_with_microtvm/micro_tvmc.html">
         Executing a Tiny Model with TVMC Micro
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 current active has-children">
      <a class="reference internal" href="index.html">
       拓展 TVM
      </a>
      <input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
      <label for="toctree-checkbox-17">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul class="current">
       <li class="toctree-l4">
        <a class="reference internal" href="low_level_custom_pass.html">
         编写定制 Pass
        </a>
       </li>
       <li class="toctree-l4 current active">
        <a class="current reference internal" href="#">
         如何使用 TVM Pass Infra
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="use_pass_instrument.html">
         如何使用 TVM Pass Instrument
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="bring_your_own_datatypes.html">
         自定义 TVM 数据类型
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../profile/index.html">
       模型剖析
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../profile/papi.html">
         PAPI 快速上手
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../errors.html">
       Handle TVM Errors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../faq.html">
       Frequently Asked Questions
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../developer-guide.html">
   Developer Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dev/tutorial/index.html">
     Developer Tutorial
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/tutorial/codebase_walkthrough.html">
       TVM Codebase Walkthrough by Example
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dev/how_to/how_to.html">
     Developer How-To Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/debugging_tvm.html">
       Debugging TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/relay_add_op.html">
       Adding an Operator to Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/relay_add_pass.html">
       Adding a Compiler Pass to Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/relay_bring_your_own_codegen.html">
       Bring Your Own Codegen To TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/pytest_target_parametrization.html">
       Python Target Parametrization
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../arch/index.html">
   Design and Architecture
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/runtime.html">
     TVM Runtime System
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/debugger.html">
     Debugger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/virtual_machine.html">
     将 VM 放入 TVM：Relay Virtual Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/introduction_to_module_serialization.html">
     模块序列化简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/pass_infra.html">
     Pass Infrastructure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/device_target_interactions.html">
     Device/Target Interactions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/inferbound.html">
     InferBound Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/hybrid_script.html">
     Hybrid Frontend Developer Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/relay_intro.html">
     Relay IR 简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/relay_op_strategy.html">
     Relay 算子策略
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/convert_layout.html">
     Convert Layout Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/benchmark.html">
     基准性能日志格式
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/frontend/tensorflow.html">
     TensorFlow Frontend
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/security.html">
     安全指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/microtvm_design.html">
     microTVM Design Document
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/microtvm_project_api.html">
     microTVM Project API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/model_library_format.html">
     Model 库格式
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../topic-guides.html">
   Topic Guides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../topic/microtvm/index.html">
     microTVM: TVM on bare-metal
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../topic/vta/index.html">
     VTA: Versatile Tensor Accelerator
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../topic/vta/install.html">
       VTA Installation Guide
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../topic/vta/dev/index.html">
       VTA Design and Developer Guide
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
      <label for="toctree-checkbox-25">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/dev/config.html">
         VTA Configuration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/dev/hardware.html">
         VTA Hardware Guide
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../topic/vta/tutorials/index.html">
       VTA 教程
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
      <label for="toctree-checkbox-26">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/vta_get_started.html">
         VTA 入门
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/matrix_multiply.html">
         简单的矩阵乘法
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/frontend/index.html">
         编译深度学习模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/optimize/index.html">
         优化 Tensor 算子
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/autotvm/index.html">
         自动调优
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../reference-guide.html">
   Reference Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
  <label for="toctree-checkbox-27">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../reference/langref/index.html">
     Language Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
    <label for="toctree-checkbox-28">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/langref/relay_expr.html">
       Expressions in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/langref/relay_type.html">
       Relay’s Type System
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/langref/relay_adt.html">
       Algebraic Data Types in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/langref/relay_op.html">
       Relay Core Tensor Operators
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/langref/relay_pattern.html">
       Pattern Matching in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/langref/hybrid_script.html">
       Hybrid Frontend Language Reference
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../reference/api/python/index.html">
     Python API
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/runtime.html">
       tvm.runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/ndarray.html">
       tvm.runtime.ndarray
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/error.html">
       tvm.error
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/ir/module.html">
       tvm.ir.module
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/ir/index.html">
       tvm.ir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/target.html">
       tvm.target
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/tir.html">
       tvm.tir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/te.html">
       tvm.te
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/driver.html">
       tvm.driver
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/index.html">
       tvm.relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/frontend.html">
       tvm.relay.frontend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/nn.html">
       tvm.relay.nn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/vision.html">
       tvm.relay.vision
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/image.html">
       tvm.relay.image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/transform.html">
       tvm.relay.transform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/analysis.html">
       tvm.relay.analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/backend.html">
       tvm.relay.backend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/dataflow_pattern.html">
       tvm.relay.dataflow_pattern
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/relay/testing.html">
       tvm.relay.testing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/autotvm.html">
       tvm.autotvm
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/auto_scheduler.html">
       tvm.auto_scheduler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/rpc.html">
       tvm.rpc
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/micro.html">
       tvm.micro
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/contrib.html">
       tvm.contrib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/graph_executor.html">
       tvm.contrib.graph_executor
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/topi.html">
       tvm.topi
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../reference/api/python/vta/index.html">
       vta
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../reference/api/links.html">
     Other APIs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../reference/publications.html">
     Publications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../refs/index.html">
   参考
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
  <label for="toctree-checkbox-30">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../refs/_ffi/index.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       _ffi
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/base.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.base
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/libinfo.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.libinfo
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/object.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi._ctypes.object
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/registry.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.registry
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/runtime_ctypes.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.runtime_ctypes
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/docs/how_to/extend_tvm/use_pass_infra.ipynb.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> 导航
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#relay">
   创建 Relay 程序示例
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   优化程序
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#passes">
     手动应用优化 passes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sequential-passes">
     使用 Sequential 来应用 Passes 序列
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#python-pass">
   使用 Python 装饰器实现 Pass
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pass">
   调试 Pass
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   小结
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>如何使用 TVM Pass Infra</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> 导航 </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#relay">
   创建 Relay 程序示例
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   优化程序
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#passes">
     手动应用优化 passes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sequential-passes">
     使用 Sequential 来应用 Passes 序列
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#python-pass">
   使用 Python 装饰器实现 Pass
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pass">
   调试 Pass
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   小结
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="tvm-pass-infra">
<h1>如何使用 TVM Pass Infra<a class="headerlink" href="#tvm-pass-infra" title="此标题的永久链接">#</a></h1>
<p><strong>原作者</strong>: <a class="reference external" href="https://github.com/zhiics">Zhi Chen</a></p>
<p>随着在 Relay/tir 中优化 pass 数量的增加，手动执行它们并维护它们的依赖关系变得非常棘手。因此，TVM 引入了 infrastructure 来管理优化 pass，并使其适用于 TVM 堆栈中 IR 的不同层。</p>
<p>Relay/tir 程序的优化可以应用在不同的粒度上，即函数级 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/relay/transform.html#tvm.relay.transform.FunctionPass" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.relay.transform.FunctionPass</span></code></a>/<a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/tir.html#tvm.tir.transform.PrimFuncPass" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.tir.transform.PrimFuncPass</span></code></a> 和模块级 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.transform.ModulePass" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.transform.ModulePass</span></code></a>。或者用户可以依赖于 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.transform.Sequential" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.transform.Sequential</span></code></a> 在 Relay/tir 程序上应用 pass 序列，其中 pass 之间的依赖性可以由 <code class="docutils literal notranslate"><span class="pre">pass</span> <span class="pre">infra</span></code> 解析。有关每种 pass 的详细信息，请参阅 <a class="reference internal" href="../../arch/pass_infra.html#pass-infra"><span class="std std-ref">Pass Infrastructure</span></a>。</p>
<p>本教程主要演示开发人员如何使用 pass infra 执行某种优化，并为 Relay 程序创建优化管道。同样的方法也可以用于 tir。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
import tvm
import tvm.relay as relay
</pre></div>
</div>
</div>
</div>
<section id="relay">
<h2>创建 Relay 程序示例<a class="headerlink" href="#relay" title="此标题的永久链接">#</a></h2>
<p>首先，为创建简单的 Relay 程序。本教程中的示例将使用这个程序进行各种优化。类似地，用户可以编写 tir 原语函数并应用 tir passes。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def example():
    shape = (1, 64, 54, 54)
    c_data = np.empty(shape).astype(&quot;float32&quot;)
    c = relay.const(c_data)
    weight = relay.var(&quot;weight&quot;, shape=(64, 64, 3, 3))
    x = relay.var(&quot;x&quot;, relay.TensorType((1, 64, 56, 56), &quot;float32&quot;))
    conv = relay.nn.conv2d(x, weight, kernel_size=(3, 3))
    y = relay.add(c, c)
    y = relay.multiply(y, relay.const(2, &quot;float32&quot;))
    y = relay.add(conv, y)
    z = relay.add(y, c)
    z1 = relay.add(y, c)
    z2 = relay.add(z, z1)
    return relay.Function([x, weight], z2)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id1">
<h2>优化程序<a class="headerlink" href="#id1" title="此标题的永久链接">#</a></h2>
<p>现在要优化程序。Relay 具有许多优化功能。选择其中一些应用到这个示例程序中。</p>
<p>有多种方法来优化 Relay 程序。下面将分别提供它们的示例。</p>
<section id="passes">
<h3>手动应用优化 passes<a class="headerlink" href="#passes" title="此标题的永久链接">#</a></h3>
<p>创建 Relay 模块，它包含一个或多个用于优化的 Relay 函数。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>f = example()
mod = tvm.IRModule.from_expr(f)
print(mod)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>def @main(%x: Tensor[(1, 64, 56, 56), float32], %weight: Tensor[(64, 64, 3, 3), float32]) {
  %0 = add(meta[relay.Constant][0], meta[relay.Constant][0]);
  %1 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0], kernel_size=[3, 3]);
  %2 = multiply(%0, 2f);
  %3 = add(%1, %2);
  %4 = add(%3, meta[relay.Constant][0]);
  %5 = add(%3, meta[relay.Constant][0]);
  add(%4, %5)
}
</pre></div>
</div>
</div>
</div>
<p>可以对模块应用常量折叠。</p>
<p><code class="docutils literal notranslate"><span class="pre">fold_const</span></code> 是不带任何参数的回调函数。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fold_const = relay.transform.FoldConstant()
</pre></div>
</div>
</div>
</div>
<p>对给定的模块调用 pass。注意，常量折叠传递在函数级工作。也就是说，模块中的每个函数都将被优化应用。用户不需要手动遍历各个函数来应用此传递。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>mod = fold_const(mod)
# 可以从更新的程序中看到，常数是折叠的。
print(mod)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %3 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */
}
</pre></div>
</div>
</div>
</div>
<p>以类似的方式应用更多的优化。例如，可以消除  <code class="docutils literal notranslate"><span class="pre">z</span></code> 和 <code class="docutils literal notranslate"><span class="pre">z1</span></code> 使用的常见表达式。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>mod = relay.transform.EliminateCommonSubexpr()(mod)
print(mod)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
}
</pre></div>
</div>
</div>
</div>
<p>一些优化，如融合，也是参数化的。例如，opt 级别 0 将不允许算子融合在一起。用户可以通过 <code class="docutils literal notranslate"><span class="pre">fuse_opt_level</span></code> 来启用它。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>mod = relay.transform.FuseOps(fuse_opt_level=0)(mod)

# 可以观察到，优化后的模块包含的函数只有 primitive op
print(mod)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %0 = fn (%p03: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p12: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    nn.conv2d(%p03, %p12, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %1 = %0(%x, %weight) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %2 = fn (%p02: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p11: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    add(%p02, %p11) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3 = %2(%1, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %4 = fn (%p01: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p1: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    add(%p01, %p1) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %5 = %4(%3, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %6 = fn (%p0: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    add(%p0, %p0) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %6(%5) /* ty=Tensor[(1, 64, 54, 54), float32] */
}
</pre></div>
</div>
</div>
</div>
</section>
<section id="sequential-passes">
<h3>使用 Sequential 来应用 Passes 序列<a class="headerlink" href="#sequential-passes" title="此标题的永久链接">#</a></h3>
<p>像上面那样应用 pass 实际上是很乏味的，它可能需要用户更好地理解它们之间的依赖关系。例如，fusion 目前在 let 绑定上不能很好地工作。因此，如果在融合之前应用  <code class="xref py py-func docutils literal notranslate"><span class="pre">relay.transform.ToANormalForm()</span></code>，将无法融合可融合的算子，因为此 pass 为每个表达式生成 let 绑定，以规范化 Relay 程序。</p>
<p>因此，Relay 提供了 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.transform.Sequential" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.transform.Sequential</span></code></a>，通过指定每个 pass 所需的 passes 并将它们打包为一个整体来执行，从而使开发人员不必明确地处理这些问题。例如，现在可以使用 sequential 样式应用相同的 pass，如下所示。<a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.transform.Sequential" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.transform.Sequential</span></code></a> 与 <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential">torch.nn.sequential</a> 和 <a class="reference external" href="https://mxnet.apache.org/api/python/docs/_modules/mxnet/gluon/block.html">mxnet.gluon.block</a> 类似。</p>
<p>例如，<code class="docutils literal notranslate"><span class="pre">torch.nn.sequential</span></code> 用于包含 PyTorch 模块序列，这些模块将被添加以构建网络。它主要关注网络层。相反，pass infra 中的 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.transform.Sequential" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.transform.Sequential</span></code></a> 作用于优化 pass。</p>
<p>下面通过 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.transform.Sequential" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.transform.Sequential</span></code></a> 执行一些传递：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>f = example()
mod = tvm.IRModule.from_expr(f)
# Glob 感兴趣的 passes.
seq = tvm.transform.Sequential(
    [
        relay.transform.FoldConstant(),
        relay.transform.EliminateCommonSubexpr(),
        relay.transform.FuseOps(fuse_opt_level=2),
    ]
)
mod1 = seq(mod)
print(mod1)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %4 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %3 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %4(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}
</pre></div>
</div>
</div>
</div>
<p>从变换后的 Relay 程序中，可以看到仍然有两个相同的加法运算。这是因为实际上并没有执行 <code class="docutils literal notranslate"><span class="pre">EliminateCommonSubexpr</span></code>。原因是在 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.transform.Sequential" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.transform.Sequential</span></code></a> 下，默认只执行优化级别小于或等于 2 的传递。然而，pass infra 为用户提供了配置接口，以定制他们想要执行的优化级别。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>with tvm.transform.PassContext(opt_level=3):
    mod2 = seq(mod)
print(mod2)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}
</pre></div>
</div>
</div>
</div>
<p>现在可以看到，两个相同的加法项中只有一个被保留了。</p>
<p>此外，用户可以使用 <code class="docutils literal notranslate"><span class="pre">disabled_pass</span></code> 配置有选择地禁用一些传递，这类似于通用编译器（如 Clang 和 GCC）使用的 <code class="docutils literal notranslate"><span class="pre">-fno-xxx</span></code> 选项。例如，可以如下所示禁用 <code class="docutils literal notranslate"><span class="pre">EliminateCommonSubexpr</span></code>。打印的模块将再次显示两个相同的加法运算。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>with tvm.transform.PassContext(opt_level=3, disabled_pass=[&quot;EliminateCommonSubexpr&quot;]):
    mod3 = seq(mod)
print(mod3)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %4 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %3 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %4(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="python-pass">
<h2>使用 Python 装饰器实现 Pass<a class="headerlink" href="#python-pass" title="此标题的永久链接">#</a></h2>
<p>下一个示例演示了如何使用 Python 装饰器借助 pass infra 编排定制的优化管道。这个功能大大简化了 pass 的实现。例如，用户可以简单地定义装饰类来进行函数级优化，如下面的示例所示。<code class="docutils literal notranslate"><span class="pre">transform_function</span></code> 包装类，用 <code class="docutils literal notranslate"><span class="pre">c</span></code> 的倍数替换所有常量。稍后，将访问给定模块中的每个函数，并在调用自定义传递时替换函数中的每个常量。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>@relay.transform.function_pass(opt_level=1)
class CustomPipeline:
    &quot;&quot;&quot;Simple test function to replace one argument to another.&quot;&quot;&quot;

    def __init__(self, multiplier):
        self.multiplier = multiplier

    # This function can define a pass.
    def transform_function(self, func, mod, ctx):
        obj = self

        class ReplaceConstant(tvm.relay.ExprMutator):
            def visit_constant(self, c):
                return relay.multiply(obj.multiplier, c)

        return ReplaceConstant().visit(func)


f = example()
mod = tvm.IRModule.from_expr(f)
custom_pass = CustomPipeline(multiplier=relay.const(3, &quot;float32&quot;))
assert custom_pass.info.name == &quot;CustomPipeline&quot;
mod3 = custom_pass(mod)
print(mod3)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %0 = multiply(3f /* ty=float32 */, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %1 = add(%0, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %2 = multiply(3f /* ty=float32 */, 2f /* ty=float32 */) /* ty=float32 */;
  %3 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %4 = multiply(%1, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %5 = add(%3, %4) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %6 = add(%5, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  %7 = add(%5, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;
  add(%6, %7) /* ty=Tensor[(1, 64, 54, 54), float32] */
}
</pre></div>
</div>
</div>
</div>
</section>
<section id="pass">
<h2>调试 Pass<a class="headerlink" href="#pass" title="此标题的永久链接">#</a></h2>
<p>TVM 为用户提供了即插即用风格（plug-and-play）的调试传递，它通过特殊的传递（ <code class="docutils literal notranslate"><span class="pre">PrintIR</span></code> ） 转储（dump）整个模块的 IR，在完成某个传递后打印 IR。对 sequential 传递示例稍加修改的版本如下所示，以便为 <code class="docutils literal notranslate"><span class="pre">FoldConstant</span></code> 优化启用 IR 转储。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>f = example()
mod = tvm.IRModule.from_expr(f)
seq = tvm.transform.Sequential(
    [
        relay.transform.FoldConstant(),
        tvm.transform.PrintIR(),
        relay.transform.EliminateCommonSubexpr(),
        relay.transform.FuseOps(),
    ]
)
</pre></div>
</div>
</div>
</div>
<p>通过在 <code class="docutils literal notranslate"><span class="pre">FoldConstant</span></code> 之后插入 <code class="docutils literal notranslate"><span class="pre">PrintIR</span></code>，当 <code class="docutils literal notranslate"><span class="pre">FoldConstant</span></code> 完成时，pass infra 将转储模块 IR。用户可以在想要调试的任何 pass 之后插入它，以查看优化效果。</p>
<p>有一个更灵活的调试机制。可以实现 <code class="docutils literal notranslate"><span class="pre">PassInstrument</span></code> 类来执行任意代码，不仅在每次传递之前和/或之后，还可以在进入/退出 <code class="docutils literal notranslate"><span class="pre">PassContext</span></code> 时执行。查看 <a class="reference internal" href="../../arch/pass_infra.html#pass-instrument-cpp-backend"><span class="std std-ref">Pass Instrument</span></a> 了解更多信息。</p>
<p>这里使用 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.instrument.pass_instrument" title="（在 tvm v0.11.dev0）"><code class="xref py py-func docutils literal notranslate"><span class="pre">tvm.instrument.pass_instrument()</span></code></a> 装饰器，实现 PassInsturment 类在每次 Pass 执行前打印 IR：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>@tvm.instrument.pass_instrument
class PrintIR:
    &quot;&quot;&quot;Print the name of the pass, the IR, only before passes execute.&quot;&quot;&quot;

    def run_before_pass(self, mod, info):
        print(&quot;Running pass: {}&quot;, info)
        print(mod)


with tvm.transform.PassContext(opt_level=3, instruments=[PrintIR()]):
    with tvm.target.Target(&quot;llvm&quot;):
        # Perform the optimizations.
        mod = seq(mod)
print(mod)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Running pass: {} The meta data of the pass - pass name: sequential, opt_level: 0, required passes: []

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: FoldConstant, opt_level: 2, required passes: []

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: PrintIR, opt_level: 0, required passes: []

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: EliminateCommonSubexpr, opt_level: 3, required passes: [
InferType, ]

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: FuseOps, opt_level: 0, required passes: [
InferType, ]

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []

def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}


def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[09:34:18] /workspace/tvm/src/ir/transform.cc:655: PrintIR():
#[version = &quot;0.0.5&quot;]
def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -&gt; Tensor[(1, 64, 54, 54), float32] {
  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -&gt; Tensor[(1, 64, 54, 54), float32] {
    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;
    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */
  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -&gt; Tensor[(1, 64, 54, 54), float32] */;
  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */
}

/* For debugging purposes the metadata section has been omitted.
 * If you would like to see the full metadata section you can set the 
 * option to `True` when invoking `astext`. 
 */
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2>小结<a class="headerlink" href="#id2" title="此标题的永久链接">#</a></h2>
<p>本教程介绍了如何使用 pass infra 更方便地在 TVM 中编写和调用 pass。本文还讨论了调用 pass 的不同方法。使用 <a class="reference external" href="https://tvm.apache.org/docs/reference/api/python/ir.html#tvm.transform.Sequential" title="（在 tvm v0.11.dev0）"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvm.transform.Sequential</span></code></a> 可以很大程度上帮助用户简化处理多个优化传递及其依赖关系的工作。此外，还提供了示例来说明如何使用 <code class="docutils literal notranslate"><span class="pre">PrintIR</span></code> 和跟踪调试 pass。</p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="low_level_custom_pass.html" title="上一页 页">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">上一页</p>
            <p class="prev-next-title">编写定制 Pass</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="use_pass_instrument.html" title="下一页 页">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">下一页</p>
        <p class="prev-next-title">如何使用 TVM Pass Instrument</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By xinetzone<br/>
  
      &copy; Copyright 2022, xinetzone.<br/>
    Last updated on 2023-02-02, 20:15:57.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>