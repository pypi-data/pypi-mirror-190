
<!DOCTYPE html>

<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Convert Layout Pass &#8212; TVM  文档</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../_static/translations.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <link rel="icon" href="../../_static/tvm-logo-square.png"/>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="基准性能日志格式" href="benchmark.html" />
    <link rel="prev" title="Relay 算子策略" href="relay_op_strategy.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh-CN">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      <img src="../../_static/../../_static/tvm-logo-small.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">TVM  文档</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   TVM Documentation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../start.html">
   Getting Started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../install/index.html">
     Installing TVM
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../install/from_source.html">
       Install from Source
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
      <label for="toctree-checkbox-3">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../install/nnpack.html">
         NNPACK Contrib Installation
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../install/docker.html">
       Docker Images
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../install/nnpack.html">
       NNPACK Contrib Installation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../contribute/index.html">
     Contributor Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/community.html">
       TVM Community Guidelines
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/pull_request.html">
       Submit a Pull Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/code_review.html">
       Code Reviews
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/committer_guide.html">
       Committer Guide
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/document.html">
       Documentation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/code_guide.html">
       Code Guide and Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/git_howto.html">
       Git Usage Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/ci.html">
       Using TVM’s CI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/release_process.html">
       Release Process
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/error_handling.html">
       Error Handling Guide
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../user-guide.html">
   用户手册
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../tutorial/index.html">
     用户指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/introduction.html">
       TVM 和模型优化的概述
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/tvmc_command_line_driver.html">
       用 TVMC 编译和优化模型
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/tvmc_python.html">
       开始使用 TVMC Python：TVM 的高级 API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/autotvm_relay_x86.html">
       用 Python 接口编译和优化模型（AutoTVM）
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/tensor_expr_get_started.html">
       使用张量表达式处理算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/autotvm_matmul_x86.html">
       用调度模板和 AutoTVM 优化算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/auto_scheduler_matmul_x86.html">
       使用自动调度优化运算
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/tensor_ir_blitz_course.html">
       TensorIR 的突击课程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/cross_compilation_and_rpc.html">
       交叉编译和RPC
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/relay_quick_start.html">
       编译深度学习模型的快速入门教程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/intro_topi.html">
       TOPI 简介
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorial/uma.html">
       通过 UMA 使您的硬件加速器 TVM-ready
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../how_to/index.html">
     How To 指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/compile_models/index.html">
       编译深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_pytorch.html">
         编译 PyTorch 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_tensorflow.html">
         Compile Tensorflow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_mxnet.html">
         编译 MXNet 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_onnx.html">
         Compile ONNX Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_keras.html">
         Compile Keras Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_tflite.html">
         Compile TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_coreml.html">
         Compile CoreML Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_darknet.html">
         Compile YOLO-V2 and YOLO-V3 in DarkNet Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_caffe2.html">
         Compile Caffe2 Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_oneflow.html">
         Compile OneFlow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_paddle.html">
         Compile PaddlePaddle Models
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/deploy/index.html">
       部署模型并集成到 TVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/cpp_deploy.html">
         使用 C++ API 部署 TVM Module
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/android.html">
         Deploy to Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/adreno.html">
         Deploy to Adreno GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/integrate.html">
         集成 TVM 到你的项目
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/hls.html">
         HLS Backend Example
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/arm_compute_lib.html">
         集成 Relay Arm
         <sup>
          ®
         </sup>
         计算库
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/tensorrt.html">
         Relay TensorRT Integration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/vitis_ai.html">
         Vitis AI Integration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/bnns.html">
         Relay BNNS Integration
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/deploy_models/index.html">
       部署深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_model_on_android.html">
         Deploy the Pretrained Model on Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_model_on_rasp.html">
         Deploy the Pretrained Model on Raspberry Pi
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_object_detection_pytorch.html">
         编译 PyTorch 目标检测模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_prequantized.html">
         使用 TVM 部署框架预量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_prequantized_tflite.html">
         Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_quantized.html">
         在 CUDA 上部署已量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_sparse.html">
         Deploy a Hugging Face Pruned Model on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_ssd_gluoncv.html">
         部署 Single Shot Multibox Detector(SSD) 模型
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_relay/index.html">
       使用 Relay
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
      <label for="toctree-checkbox-11">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/build_gcn.html">
         构建图卷积网络
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/using_external_lib.html">
         在 Relay 中使用外部库
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/using_pipeline_executor.html">
         在 Relay 中使用管道执行器
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/using_relay_viz.html">
         使用 Relay Visualizer 可视化 Relay
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_schedules/index.html">
       使用 Tensor Expression 和 Schedules
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/schedule_primitives.html">
         TVM 中的调度原语
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/reduction.html">
         Reduction
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/intrin_math.html">
         Intrinsics and Math Functions
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/scan.html">
         Scan and Recurrent Kernel
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/extern_op.html">
         外部张量函数
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tensorize.html">
         Use Tensorize to Leverage Hardware Intrinsics
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tuple_inputs.html">
         Compute and Reduce with Tuple Inputs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tedd.html">
         使用 TEDD 进行可视化
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/optimize_operators/index.html">
       优化张量算子
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
      <label for="toctree-checkbox-13">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_gemm.html">
         How to optimize GEMM on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_conv_cuda.html">
         How to optimize convolution on GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_conv_tensorcore.html">
         How to optimize convolution using TensorCores
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/tune_with_autotvm/index.html">
       Auto-Tune with Templates and AutoTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_conv2d_cuda.html">
         Tuning High Performance Convolution on NVIDIA GPUs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_cuda.html">
         Auto-tuning a Convolutional Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_x86.html">
         Auto-tuning a Convolutional Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_arm.html">
         Auto-tuning a Convolutional Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_mobile_gpu.html">
         Auto-tuning a Convolutional Network for Mobile GPU
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/tune_with_autoscheduler/index.html">
       使用自动调度器进行无模板调度
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.html">
         Auto-scheduling a Convolution Layer for GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_x86.html">
         Auto-scheduling a Neural Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_cuda.html">
         Auto-scheduling a Neural Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_arm.html">
         Auto-scheduling a Neural Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_mali.html">
         Auto-scheduling a Neural Network for mali GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_sparse_x86.html">
         Auto-scheduling Sparse Matrix Multiplication on CPU with Custom Sketch Rule
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_microtvm/index.html">
       使用 microTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_aot.html">
         microTVM Host-Driven AoT
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_autotune.html">
         使用 microTVM Autotuning
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_ethosu.html">
         在 bare metal Arm® Cortex®-M55 CPU 和 Ethos™-U55 NPU 上运行 TVM
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_reference_vm.html">
         microTVM 参考虚拟机
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_tflite.html">
         microTVM with TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_train.html">
         Training Vision Models for microTVM on Arduino
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_tvmc.html">
         Executing a Tiny Model with TVMC Micro
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/extend_tvm/index.html">
       拓展 TVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
      <label for="toctree-checkbox-17">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/low_level_custom_pass.html">
         编写定制 Pass
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/use_pass_infra.html">
         如何使用 TVM Pass Infra
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/use_pass_instrument.html">
         如何使用 TVM Pass Instrument
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/bring_your_own_datatypes.html">
         自定义 TVM 数据类型
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/profile/index.html">
       模型剖析
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/profile/papi.html">
         PAPI 快速上手
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../errors.html">
       Handle TVM Errors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../faq.html">
       Frequently Asked Questions
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../developer-guide.html">
   Developer Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dev/tutorial/index.html">
     Developer Tutorial
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/tutorial/codebase_walkthrough.html">
       TVM Codebase Walkthrough by Example
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dev/how_to/how_to.html">
     Developer How-To Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/debugging_tvm.html">
       Debugging TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_add_op.html">
       Adding an Operator to Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_add_pass.html">
       Adding a Compiler Pass to Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_bring_your_own_codegen.html">
       Bring Your Own Codegen To TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/pytest_target_parametrization.html">
       Python Target Parametrization
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Design and Architecture
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="runtime.html">
     TVM Runtime System
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="debugger.html">
     Debugger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="virtual_machine.html">
     将 VM 放入 TVM：Relay Virtual Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="introduction_to_module_serialization.html">
     模块序列化简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pass_infra.html">
     Pass Infrastructure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="device_target_interactions.html">
     Device/Target Interactions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inferbound.html">
     InferBound Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hybrid_script.html">
     Hybrid Frontend Developer Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="relay_intro.html">
     Relay IR 简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="relay_op_strategy.html">
     Relay 算子策略
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Convert Layout Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="benchmark.html">
     基准性能日志格式
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="frontend/tensorflow.html">
     TensorFlow Frontend
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="security.html">
     安全指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="microtvm_design.html">
     microTVM Design Document
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="microtvm_project_api.html">
     microTVM Project API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="model_library_format.html">
     Model 库格式
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../topic-guides.html">
   Topic Guides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../topic/microtvm/index.html">
     microTVM: TVM on bare-metal
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../topic/vta/index.html">
     VTA: Versatile Tensor Accelerator
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../topic/vta/install.html">
       VTA Installation Guide
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../topic/vta/dev/index.html">
       VTA Design and Developer Guide
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
      <label for="toctree-checkbox-25">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/dev/config.html">
         VTA Configuration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/dev/hardware.html">
         VTA Hardware Guide
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../topic/vta/tutorials/index.html">
       VTA 教程
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
      <label for="toctree-checkbox-26">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/vta_get_started.html">
         VTA 入门
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/matrix_multiply.html">
         简单的矩阵乘法
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/frontend/index.html">
         编译深度学习模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/optimize/index.html">
         优化 Tensor 算子
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/autotvm/index.html">
         自动调优
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../reference-guide.html">
   Reference Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
  <label for="toctree-checkbox-27">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../reference/langref/index.html">
     Language Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
    <label for="toctree-checkbox-28">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_expr.html">
       Expressions in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_type.html">
       Relay’s Type System
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_adt.html">
       Algebraic Data Types in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_op.html">
       Relay Core Tensor Operators
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_pattern.html">
       Pattern Matching in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/hybrid_script.html">
       Hybrid Frontend Language Reference
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../reference/api/python/index.html">
     Python API
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/runtime.html">
       tvm.runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/ndarray.html">
       tvm.runtime.ndarray
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/error.html">
       tvm.error
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/ir/module.html">
       tvm.ir.module
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/ir/index.html">
       tvm.ir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/target.html">
       tvm.target
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/tir.html">
       tvm.tir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/te.html">
       tvm.te
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/driver.html">
       tvm.driver
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/index.html">
       tvm.relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/frontend.html">
       tvm.relay.frontend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/nn.html">
       tvm.relay.nn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/vision.html">
       tvm.relay.vision
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/image.html">
       tvm.relay.image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/transform.html">
       tvm.relay.transform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/analysis.html">
       tvm.relay.analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/backend.html">
       tvm.relay.backend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/dataflow_pattern.html">
       tvm.relay.dataflow_pattern
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/testing.html">
       tvm.relay.testing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/autotvm.html">
       tvm.autotvm
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/auto_scheduler.html">
       tvm.auto_scheduler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/rpc.html">
       tvm.rpc
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/micro.html">
       tvm.micro
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/contrib.html">
       tvm.contrib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/graph_executor.html">
       tvm.contrib.graph_executor
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/topi.html">
       tvm.topi
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/vta/index.html">
       vta
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/api/links.html">
     Other APIs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/publications.html">
     Publications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../refs/index.html">
   参考
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
  <label for="toctree-checkbox-30">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../refs/_ffi/index.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       _ffi
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/base.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.base
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/libinfo.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.libinfo
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/object.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi._ctypes.object
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/registry.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.registry
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/runtime_ctypes.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.runtime_ctypes
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/docs/arch/convert_layout.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> 导航
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   1. Background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-and-overview">
   2. Motivation and Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#design">
   3. Design
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#usage">
   4. Usage
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Convert Layout Pass</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> 导航 </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   1. Background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-and-overview">
   2. Motivation and Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#design">
   3. Design
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#usage">
   4. Usage
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="convert-layout-pass">
<h1>Convert Layout Pass<a class="headerlink" href="#convert-layout-pass" title="此标题的永久链接">#</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/anijain2305">Animesh Jain</a></p>
<section id="background">
<h2>1. Background<a class="headerlink" href="#background" title="此标题的永久链接">#</a></h2>
<p>Data layout format describes how the data is laid out in the memory. For example, Tensorflow framework default data layout for convolution operator is NHWC, i.e, the data is 4-dimensions and is laid out in row-major format with N being the first dimension and C being the last dimension. Data layout has a major role in model performance, significantly affecting spatial and temporal locality. For example, Intel x86 backend in TVM prefers layout as NCHWc where the C dimension is tiled in 2 dimensions to exploit data locality efficiently. Similarly, CUDA backend prefers the data layout to be in NCHW format.</p>
<p>Essentially, TVM has to deal with data layouts throughout the compiler toolchain - Framework parsers, Relay layout transformations, and TOPI schedules. As we move towards third-party codegen integration, which might have their own data layout restrictions, handling layouts at all levels in TVM toolchain is going to become even more challenging. Therefore, we developed a new Relay pass - <strong>ConvertLayout</strong> – to reduce some of the complications that arise due to layout handling.</p>
<p>If you directly want to understand the usage of ConvertLayout Pass, directly jump to Section 4 - Usage.</p>
</section>
<section id="motivation-and-overview">
<h2>2. Motivation and Overview<a class="headerlink" href="#motivation-and-overview" title="此标题的永久链接">#</a></h2>
<p>Let’s look at a simple scenario to understand the complications that arise due to different layouts - Suppose we want to compile a Tensorflow NHWC graph for an ARM edge device. But, suppose we currently support only NCHW schedules in TOPI for ARM. So, there is a mismatch between framework layout and TOPI-supported layout. One way to deal with this mismatch is to insert layout transforms before each and after convolution, such that resulting convolution has NCHW input data layout and can use TOPI schedules. However, this can lead to performance degradation because of the presence of too many layout transforms.</p>
<p>We encountered similar problems in other use cases as well</p>
<ul class="simple">
<li><p>No way to run TFLite graphs on Nvidia GPUs. TOPI has NCHW-only schedules for GPUs.</p></li>
<li><p>Ever-complicating logic in AlterOpLayout for convolution to support different pairs of layout transformations.</p></li>
<li><p>Sub-optimal performance for TF graphs due to extra layout transforms.</p></li>
<li><p>Complication in third-party codegen integrations like TensorRT that prefers data layout to be in one format.</p></li>
</ul>
<p>To solve these problems, we introduced <em>ConvertLayout</em> pass that sets up the infrastructure to change the data layout of the whole graph with minimal number of data layout transforms. In ideal cases, we will have only 2 layout transforms for data, one at the start and one at the end. An example to show the transformation is below</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Original graph - 2 convolutions in NHWC format.</span>
<span class="n">fn</span> <span class="p">(</span><span class="o">%</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">float32</span><span class="p">],</span> <span class="o">%</span><span class="n">weight1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">float32</span><span class="p">],</span> <span class="o">%</span><span class="n">weight2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">float32</span><span class="p">])</span> <span class="p">{</span>
  <span class="o">%</span><span class="mi">0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="o">%</span><span class="n">x</span><span class="p">,</span> <span class="o">%</span><span class="n">weight1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">data_layout</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">,</span> <span class="n">kernel_layout</span><span class="o">=</span><span class="s2">&quot;HWIO&quot;</span><span class="p">);</span>
  <span class="o">%</span><span class="mi">1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="o">%</span><span class="mi">0</span><span class="p">);</span>
  <span class="o">%</span><span class="mi">2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="o">%</span><span class="mi">1</span><span class="p">,</span> <span class="o">%</span><span class="n">weight2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">data_layout</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">,</span> <span class="n">kernel_layout</span><span class="o">=</span><span class="s2">&quot;HWIO&quot;</span><span class="p">);</span>
  <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="o">%</span><span class="mi">2</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># After ConvertLayout - For data, there is a transform at the start and at the end.</span>
<span class="c1"># For weights, there are transforms to adapt to NCHW layout. These will be removed by FoldConstant pass.</span>
<span class="n">fn</span> <span class="p">(</span><span class="o">%</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">float32</span><span class="p">],</span> <span class="o">%</span><span class="n">weight1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">float32</span><span class="p">],</span> <span class="o">%</span><span class="n">weight2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">float32</span><span class="p">])</span> <span class="p">{</span>
  <span class="o">%</span><span class="mi">0</span> <span class="o">=</span> <span class="n">layout_transform</span><span class="p">(</span><span class="o">%</span><span class="n">x</span><span class="p">,</span> <span class="n">src_layout</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">,</span> <span class="n">dst_layout</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span> <span class="o">/*</span> <span class="n">ty</span><span class="o">=</span><span class="n">Tensor</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">),</span> <span class="n">float32</span><span class="p">]</span> <span class="o">*/</span><span class="p">;</span>
  <span class="o">%</span><span class="mi">1</span> <span class="o">=</span> <span class="n">layout_transform</span><span class="p">(</span><span class="o">%</span><span class="n">weight1</span><span class="p">,</span> <span class="n">src_layout</span><span class="o">=</span><span class="s2">&quot;HWIO&quot;</span><span class="p">,</span> <span class="n">dst_layout</span><span class="o">=</span><span class="s2">&quot;OIHW&quot;</span><span class="p">)</span> <span class="o">/*</span> <span class="n">ty</span><span class="o">=</span><span class="n">Tensor</span><span class="p">[(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">float32</span><span class="p">]</span> <span class="o">*/</span><span class="p">;</span>
  <span class="o">%</span><span class="mi">2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="o">%</span><span class="mi">0</span><span class="p">,</span> <span class="o">%</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="o">/*</span> <span class="n">ty</span><span class="o">=</span><span class="n">Tensor</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">),</span> <span class="n">float32</span><span class="p">]</span> <span class="o">*/</span><span class="p">;</span>
  <span class="o">%</span><span class="mi">3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="o">%</span><span class="mi">2</span><span class="p">)</span> <span class="o">/*</span> <span class="n">ty</span><span class="o">=</span><span class="n">Tensor</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">),</span> <span class="n">float32</span><span class="p">]</span> <span class="o">*/</span><span class="p">;</span>
  <span class="o">%</span><span class="mi">4</span> <span class="o">=</span> <span class="n">layout_transform</span><span class="p">(</span><span class="o">%</span><span class="n">weight2</span><span class="p">,</span> <span class="n">src_layout</span><span class="o">=</span><span class="s2">&quot;HWIO&quot;</span><span class="p">,</span> <span class="n">dst_layout</span><span class="o">=</span><span class="s2">&quot;OIHW&quot;</span><span class="p">)</span> <span class="o">/*</span> <span class="n">ty</span><span class="o">=</span><span class="n">Tensor</span><span class="p">[(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">float32</span><span class="p">]</span> <span class="o">*/</span><span class="p">;</span>
  <span class="o">%</span><span class="mi">5</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="o">%</span><span class="mi">3</span><span class="p">,</span> <span class="o">%</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="o">/*</span> <span class="n">ty</span><span class="o">=</span><span class="n">Tensor</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">),</span> <span class="n">float32</span><span class="p">]</span> <span class="o">*/</span><span class="p">;</span>
  <span class="o">%</span><span class="mi">6</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="o">%</span><span class="mi">5</span><span class="p">)</span> <span class="o">/*</span> <span class="n">ty</span><span class="o">=</span><span class="n">Tensor</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">),</span> <span class="n">float32</span><span class="p">]</span> <span class="o">*/</span><span class="p">;</span>
  <span class="n">layout_transform</span><span class="p">(</span><span class="o">%</span><span class="mi">6</span><span class="p">,</span> <span class="n">src_layout</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span> <span class="n">dst_layout</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">)</span> <span class="o">/*</span> <span class="n">ty</span><span class="o">=</span><span class="n">Tensor</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">float32</span><span class="p">]</span> <span class="o">*/</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="design">
<h2>3. Design<a class="headerlink" href="#design" title="此标题的永久链接">#</a></h2>
<p>Before delving into ConvertLayout pass, let’s categorize the operators into 3 categories based on their sensitivity to data layouts. This categorization will be useful later to understand Convertlayout pass details.</p>
<ul class="simple">
<li><p><strong>Layout agnostic</strong> - Relu, pow etc. These operators are not affected, neither functionality nor performance, by data layouts.</p></li>
<li><p><strong>Lightly-layout sensitive</strong> - pad, concatenate, reduce ops like sum etc. These operators have some attributes that are functionally affected if we do a layout transformation before them. However, performance-wise, the difference is not significant. For these operators, it is beneficial to just adapt to the previous operator output data layout.</p></li>
<li><p><strong>Heavily-layout sensitive</strong> - Convolution, conv2d_transpose etc. These operators are heavily affected, both functionally and performance-wise, by data layouts. They also have data layout as the op attribute. Typically, it is beneficial to modify the input data layouts for these operators (if its not a performant data layout), while the rest of <em>layout agnostic</em> and <em>lightly-layout sensitive</em> operators adapt to the layout governed by the output of these <em>heavliy-layout sensitive</em> operators.</p></li>
</ul>
<p>Let us now look at two relevant Relay operator properties. Each relay operator has properties, like InferType, that can be defined by a TVM developer. Typically, a Relay pass traverses the graph operator-by-operator and reads these operator properties. For example, InferType pass looks at the InferType property of on operator, determines its output shape and type, and then passes it to the next operator InferType property. Similarly, in our context, we have 2 such properties - <em>FTVMConvertLayout</em> and <em>FInferCorrectLayout</em>. ConvertLayout pass traverses the graph and looks at these 2 properties along with an automatic layout transform insertion module to handle data layouts. So, the whole process can be broken down into 3 steps:</p>
<ul class="simple">
<li><p>Run FTVMConvertLayout property - This allows the developers to transform the original Relay expr into a new Relay expr with new layouts, allowing user-defined layout alteration. There is a python callback for developer’s ease. This is used only for heavily-layout sensitive operators.</p></li>
<li><p>Run FTVMInferCorretLayout property - We can view this as layout inference. It looks at the original input layout and the new input layouts, which are either coming from previous operator or from the FTVMConvertLayout modified expr (if it was used). This can be used by lightly-layout sensitive operators to adapt its attributes to new data layouts. Layout inference happens for each operator.</p></li>
<li><p>Automatic insertion of layout transforms - The previous step - layout inference - sets the new layout for the input exprs. If these layouts are different from the original layouts, then this component automatically inserts a layout transform. Therefore, a developer does not need to do anything for this component.</p></li>
</ul>
<p>These steps happen for each operator in sequence, where ConvertLayout pass keeps on passing the new layouts to the next operator properties, finally resulting in modifying the whole graph operator-by-operator. Now, let’s look at a couple of examples of how to define the two properties.</p>
<p><strong>FTVMConvertLayout - Python callback for layout alteration</strong> - This is used for <em>heavily-layout sensitive</em> operators. For example, one can return a new convolution operator with new data and kernel layout. The other 2 components will infer layout and insert layout transforms if needed. One example for convolution operator is as follows where we are converting to NCHW layout.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@reg</span><span class="o">.</span><span class="n">register_convert_op_layout</span><span class="p">(</span><span class="s2">&quot;nn.conv2d&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">convert_conv2d</span><span class="p">(</span><span class="n">attrs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">tinfos</span><span class="p">,</span> <span class="n">desired_layouts</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert Layout pass registration for conv2d op.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    attrs : tvm.attrs.Attrs</span>
<span class="sd">        Attributes of current convolution</span>
<span class="sd">    inputs : list of tvm.relay.Expr</span>
<span class="sd">        The args of the Relay expr to be legalized</span>
<span class="sd">    tinfos : list of types</span>
<span class="sd">        List of input and output types</span>
<span class="sd">    desired_layouts : list of layout strings</span>
<span class="sd">            List of layouts defining our desired</span>
<span class="sd">            layout for the data and kernel inputs respectively.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : tvm.relay.Expr</span>
<span class="sd">        The transformed expr</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relay</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="n">new_attrs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">attrs</span><span class="p">)</span>

    <span class="c1"># We expect 2 desired layouts to be specified, one for the data and one for the kernel.</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">desired_layouts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;A desired layout is expected for both of nn.conv2d&#39;s inputs&quot;</span>

    <span class="c1"># Use the first entry in desired layouts which specifies the data layout.</span>
    <span class="c1"># The expected ordering of layouts for this operator is defined by this function.</span>
    <span class="n">desired_data_layout</span><span class="p">,</span> <span class="n">desired_kernel_layout</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">desired_layouts</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">desired_data_layout</span> <span class="o">!=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="s2">&quot;Data layout cannot be default&quot;</span>

    <span class="n">new_attrs</span><span class="p">[</span><span class="s1">&#39;data_layout&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">desired_data_layout</span>

    <span class="k">if</span> <span class="n">desired_data_layout</span> <span class="o">==</span> <span class="s1">&#39;NCHW&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">desired_kernel_layout</span> <span class="o">!=</span> <span class="s1">&#39;default&#39;</span><span class="p">:</span>
            <span class="n">new_attrs</span><span class="p">[</span><span class="s1">&#39;kernel_layout&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">desired_kernel_layout</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_attrs</span><span class="p">[</span><span class="s1">&#39;kernel_layout&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;OIHW&#39;</span>
        <span class="c1"># Actual insertion of layout transforms is taken care internally</span>
        <span class="c1"># by ConvertLayout pass.</span>
        <span class="k">return</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="o">**</span><span class="n">new_attrs</span><span class="p">)</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Layout </span><span class="si">%s</span><span class="s1"> is not yet supported&#39;</span> <span class="o">%</span> <span class="n">desired_data_layout</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>FInferCorrectLayout - Layout inference</strong> - Currently, this attribute is exposed only in C++. This function takes original input layouts and the new input layouts (passed from the previous operator or from the python callback for layout alteration), and infers the final data layouts. Layout inference is called for each operator. The usage might vary for different operator categories. For layout agnostic operators, we just want to return the new data layouts in this function. For lightly-layout and heavily-layout sensitive operators, we can change the operator attributes (like axis for concatenate, pad_width for pad) so that we can adapt to the new data layout, preventing insertion of layout transforms. Let’s look at a couple of examples to understand this better.</p>
<p>First example is for layout agnostic operators. These operators do not have any operator attributes that are affected by data layouts, so we just adapt to new layouts.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// For operator set its attributes like following</span>
<span class="c1">//          .set_attr&lt;FInferCorrectLayout&gt;(&quot;FInferCorrectLayout&quot;, ElemwiseArbitraryLayout);</span>

<span class="c1">// Take arbitrary input layouts and copy to outputs.</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">ElemwiseArbitraryLayout</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Attrs</span><span class="o">&amp;</span><span class="w"> </span><span class="n">attrs</span><span class="p">,</span>
<span class="w">                                                     </span><span class="k">const</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">new_in_layouts</span><span class="p">,</span>
<span class="w">                                                     </span><span class="k">const</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">old_in_layouts</span><span class="p">,</span>
<span class="w">                                                     </span><span class="k">const</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Array</span><span class="o">&lt;</span><span class="n">IndexExpr</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">old_in_shapes</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">Layout</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">new_in_layouts</span><span class="p">.</span><span class="n">defined</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">ICHECK_GE</span><span class="p">(</span><span class="n">new_in_layouts</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new_in_layouts</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">old_in_layouts</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">old_in_layouts</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">defined</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">old_in_layouts</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">        </span><span class="k">break</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&gt;</span><span class="p">{</span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;</span><span class="p">(</span><span class="n">old_in_layouts</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="n">ret</span><span class="p">),</span><span class="w"> </span><span class="p">{</span><span class="n">ret</span><span class="p">}};</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Second example is for a lightly-layout sensitive operator - batch normalization. BatchNorm has an axis operator that has to change when we go from NHWC to NCHW data layout. (Similar handling also needs to be for heavily-layout sensitive operators)</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">BatchNormInferCorrectLayout</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Attrs</span><span class="o">&amp;</span><span class="w"> </span><span class="n">attrs</span><span class="p">,</span>
<span class="w">                                                 </span><span class="k">const</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">new_in_layouts</span><span class="p">,</span>
<span class="w">                                                 </span><span class="k">const</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">old_in_layouts</span><span class="p">,</span>
<span class="w">                                                 </span><span class="k">const</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Array</span><span class="o">&lt;</span><span class="n">IndexExpr</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">old_in_shapes</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">BatchNormAttrs</span><span class="o">*</span><span class="w"> </span><span class="n">param</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">BatchNormAttrs</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">attrs</span><span class="p">.</span><span class="n">as</span><span class="o">&lt;</span><span class="n">BatchNormAttrs</span><span class="o">&gt;</span><span class="p">());</span>

<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">param</span><span class="o">-&gt;</span><span class="n">axis</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">param</span><span class="o">-&gt;</span><span class="n">axis</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">old_in_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">param</span><span class="o">-&gt;</span><span class="n">axis</span><span class="p">);</span>

<span class="w">  </span><span class="n">Layout</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Layout</span><span class="o">::</span><span class="n">Undef</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// For example, consider old_layout = NHWC, and new_layout = NCHW, and param-&gt;axis = 3</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">new_in_layouts</span><span class="p">.</span><span class="n">defined</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">old_in_layouts</span><span class="p">.</span><span class="n">defined</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Get the new C axis. Extract the dim in old layout. Find the index of that dim in next layout.</span>

<span class="w">    </span><span class="c1">// Following line gives bn_dim = C as old_layout = NHWC, axis = 3</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">bn_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">old_in_layouts</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">axis</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// The new_index is 1 because new_layout = NCHW and bn_dim is C</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">new_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new_in_layouts</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">IndexOf</span><span class="p">(</span><span class="n">bn_dim</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// We modify the layout-dependent attribute here - axis to 1.</span>
<span class="w">    </span><span class="n">param</span><span class="o">-&gt;</span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new_index</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Finally, we adapt to the new layout.</span>
<span class="w">    </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new_in_layouts</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>

<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">old_in_layouts</span><span class="p">.</span><span class="n">defined</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">old_in_layouts</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// In case both new and old layouts are undefined, then there is no need of a change.</span>
<span class="w">  </span><span class="c1">// ConvertLayout pass skips the automatic insertion of layout transforms in this case.</span>

<span class="w">  </span><span class="c1">// Following line is not important to tutorial. But, layout inference needs to define</span>
<span class="w">  </span><span class="c1">// the layout for all input and output data layouts. For batch norm, the other inputs</span>
<span class="w">  </span><span class="c1">// and outputs are vector having length of C dim in the input. So, we set the other</span>
<span class="w">  </span><span class="c1">// layouts as C. BN has 5 inputs, 3 outputs. The last 4 inputs and last 2 outputs</span>
<span class="w">  </span><span class="c1">// have &quot;C&quot; layout.</span>
<span class="w">  </span><span class="n">Layout</span><span class="w"> </span><span class="n">c_layout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Layout</span><span class="p">(</span><span class="s">&quot;C&quot;</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&gt;&gt;</span><span class="p">{{</span><span class="n">ret</span><span class="p">,</span><span class="w"> </span><span class="n">c_layout</span><span class="p">,</span><span class="w"> </span><span class="n">c_layout</span><span class="p">,</span><span class="w"> </span><span class="n">c_layout</span><span class="p">,</span><span class="w"> </span><span class="n">c_layout</span><span class="p">},</span>
<span class="w">                              </span><span class="p">{</span><span class="n">ret</span><span class="p">,</span><span class="w"> </span><span class="n">c_layout</span><span class="p">,</span><span class="w"> </span><span class="n">c_layout</span><span class="p">}};</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="usage">
<h2>4. Usage<a class="headerlink" href="#usage" title="此标题的永久链接">#</a></h2>
<p id="convert-layout-usage">ConvertLayout pass is extremely easy to use. The pass is not a part of default relay.build pipeline. The intended usage is to call it between the framework-to-relay parser and relay.build module call.</p>
<p>In order to specify the layouts to convert to, we create a mapping of heavily-layout sensitive operators to a list of the desired layouts for that operator. The first example below specifies data layout, we allow the kernel layout to be automatically converted to one that is supported by TVM (for that particular data layout and operator). This is specified by the use of the “default” keyword. The second example shows how we could have also converted to a specific kernel layout of our choosing. It’s worth noting that the following examples will convert to the same layouts i.e. <cite>{‘nn.conv2d’: [‘NCHW’, ‘default’]} == {‘nn.conv2d’: [‘NCHW’, ‘OIHW’]}</cite></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TFlite framework to Relay parser - Default layout is NHWC</span>
<span class="n">mod</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_tflite</span><span class="p">(</span><span class="n">tflite_model</span><span class="p">,</span>
                                         <span class="n">shape_dict</span><span class="o">=</span><span class="n">shape_dict</span><span class="p">,</span>
                                         <span class="n">dtype_dict</span><span class="o">=</span><span class="n">dtype_dict</span><span class="p">)</span>

<span class="c1"># We assume our model&#39;s heavily-layout sensitive operators only consist of nn.conv2d</span>
<span class="n">desired_layouts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;nn.conv2d&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;NCHW&#39;</span><span class="p">,</span> <span class="s1">&#39;default&#39;</span><span class="p">]}</span>

<span class="c1"># Convert the layout to NCHW</span>
<span class="c1"># RemoveUnunsedFunctions is used to clean up the graph.</span>
<span class="n">seq</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">RemoveUnusedFunctions</span><span class="p">(),</span>
                                <span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">ConvertLayout</span><span class="p">(</span><span class="n">desired_layouts</span><span class="p">)])</span>
<span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">seq</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>

<span class="c1"># Call relay compilation</span>
<span class="k">with</span> <span class="n">relay</span><span class="o">.</span><span class="n">build_config</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
     <span class="n">graph</span><span class="p">,</span> <span class="n">lib</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">desired_layouts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;nn.conv2d&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;NCHW&#39;</span><span class="p">,</span> <span class="s1">&#39;OIHW&#39;</span><span class="p">]}</span>
<span class="k">pass</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">ConvertLayout</span><span class="p">(</span><span class="n">desired_layouts</span><span class="p">)</span>
</pre></div>
</div>
<p>The ordering of the layouts is defined by the implementation of <cite>register_convert_op_layout(“OPNAME”)</cite>, you can refer to the docstring which should explicitly state the expected layout. In the examples above it’s [data_layout, kernel_layout].</p>
<p>Current implementation has support for almost all the operators commonly used in image classification models. However, if one encounters too many data layout transforms in the graph, it is highly likely that there is an operator whose layouts need special handling as described in Section 3. Some pull requests that can help in such a situation are</p>
<ul class="simple">
<li><p>Layout inference for <a class="reference external" href="https://github.com/apache/tvm/pull/4600">Batch Norm</a> - Batch normalization falls into the category of lightly-sensitive operator. The PR shows how to handle the layout inference for batch norm.</p></li>
<li><p>Python Callback for <a class="reference external" href="https://github.com/apache/tvm/pull/4335">Convolution</a>- For highly-sensitive operators, one might have to do python callback as well. The PR shows how to define a python callback function for Convolution operator.</p></li>
</ul>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="relay_op_strategy.html" title="上一页 页">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">上一页</p>
            <p class="prev-next-title">Relay 算子策略</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="benchmark.html" title="下一页 页">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">下一页</p>
        <p class="prev-next-title">基准性能日志格式</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By xinetzone<br/>
  
      &copy; Copyright 2022, xinetzone.<br/>
    Last updated on 2023-02-02, 20:15:57.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>