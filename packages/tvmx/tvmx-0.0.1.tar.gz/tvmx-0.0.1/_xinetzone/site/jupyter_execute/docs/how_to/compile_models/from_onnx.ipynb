{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Compile ONNX Models\n",
    "**Author**: [Joshua Z. Zhang](https://zhreshold.github.io/)\n",
    "\n",
    "This article is an introductory tutorial to deploy ONNX models with Relay.\n",
    "\n",
    "For us to begin with, ONNX package must be installed.\n",
    "\n",
    "A quick solution is to install protobuf compiler, and\n",
    "\n",
    "```bash\n",
    "pip install --user onnx onnxoptimizer\n",
    "```\n",
    "or please refer to official site.\n",
    "https://github.com/onnx/onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te\n",
    "import tvm.relay as relay\n",
    "from tvm.contrib.download import download_testdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained ONNX model\n",
    "The example super resolution model used here is exactly the same model in onnx tutorial\n",
    "http://pytorch.org/tutorials/advanced/super_resolution_with_caffe2.html\n",
    "we skip the pytorch model construction part, and download the saved onnx model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_url = \"\".join(\n",
    "    [\n",
    "        \"https://gist.github.com/zhreshold/\",\n",
    "        \"bcda4716699ac97ea44f791c24310193/raw/\",\n",
    "        \"93672b029103648953c4e5ad3ac3aadf346a4cdc/\",\n",
    "        \"super_resolution_0.2.onnx\",\n",
    "    ]\n",
    ")\n",
    "model_path = download_testdata(model_url, \"super_resolution.onnx\", module=\"onnx\")\n",
    "# now you have super_resolution.onnx on disk\n",
    "onnx_model = onnx.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a test image\n",
    "A single cat dominates the examples! This model takes a single input image of size\n",
    "224x224 and outputs a scaled image that is 3x greater than the input along each\n",
    "axis, a 672x672 image. Re-scale the cat image to fit this input shape then\n",
    "convert to `YCbCr`. The super resolution model will then be applied to the\n",
    "luminance (`Y`) channel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_url = \"https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true\"\n",
    "img_path = download_testdata(img_url, \"cat.png\", module=\"data\")\n",
    "img = Image.open(img_path).resize((224, 224))\n",
    "img_ycbcr = img.convert(\"YCbCr\")  # convert to YCbCr\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "x = np.array(img_y)[np.newaxis, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model with relay\n",
    "Typically ONNX models mix model input values with parameter values, with\n",
    "the input having the name `1`. This model dependent, and you should check\n",
    "with the documentation for your model to determine the full input and\n",
    "parameter name space.\n",
    "\n",
    "Passing in the shape dictionary to the `relay.frontend.from_onnx` method\n",
    "tells relay which ONNX parameters are inputs, and which are parameters, and\n",
    "provides a static definition of the input size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = \"llvm\"\n",
    "\n",
    "input_name = \"1\"\n",
    "shape_dict = {input_name: x.shape}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=1):\n",
    "    executor = relay.build_module.create_executor(\n",
    "        \"graph\", mod, tvm.cpu(0), target, params\n",
    "    ).evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute on TVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtype = \"float32\"\n",
    "tvm_output = executor(tvm.nd.array(x.astype(dtype))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results\n",
    "We put input and output image neck to neck. The luminance channel, `Y` is the output\n",
    "from the model. The chroma channels `Cb` and `Cr` are resized to match with a simple\n",
    "bicubic algorithm. The image is then recombined and converted back to `RGB`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "out_y = Image.fromarray(np.uint8((tvm_output[0, 0]).clip(0, 255)), mode=\"L\")\n",
    "out_cb = img_cb.resize(out_y.size, Image.BICUBIC)\n",
    "out_cr = img_cr.resize(out_y.size, Image.BICUBIC)\n",
    "result = Image.merge(\"YCbCr\", [out_y, out_cb, out_cr]).convert(\"RGB\")\n",
    "canvas = np.full((672, 672 * 2, 3), 255)\n",
    "canvas[0:224, 0:224, :] = np.asarray(img)\n",
    "canvas[:, 672:, :] = np.asarray(result)\n",
    "plt.imshow(canvas.astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "By default, ONNX defines models in terms of dynamic shapes. The ONNX importer\n",
    "retains that dynamism upon import, and the compiler attempts to convert the model\n",
    "into a static shapes at compile time. If this fails, there may still be dynamic\n",
    "operations in the model. Not all TVM kernels currently support dynamic shapes,\n",
    "please file an issue on discuss.tvm.apache.org if you hit an error with dynamic kernels.\n",
    "\n",
    "This particular model was build using an older version of ONNX. During the import\n",
    "phase ONNX importer will run the ONNX verifier, which may throw a `Mismatched attribute type`\n",
    "warning. Because TVM supports a number of different ONNX versions, the Relay model\n",
    "will still be valid.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}