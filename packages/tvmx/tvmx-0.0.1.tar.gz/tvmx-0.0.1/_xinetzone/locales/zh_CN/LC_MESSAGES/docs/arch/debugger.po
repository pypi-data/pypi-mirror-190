# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-05-27 12:49+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../../xin/docs/arch/debugger.rst:20
msgid "Debugger"
msgstr "调试器"

#: ../../../xin/docs/arch/debugger.rst:22
msgid ""
"TVM Debugger is an interface for debugging TVM's computation graph "
"execution. It helps to provide access to graph structures and tensor "
"values at the TVM runtime."
msgstr ""
"TVM 调试器是调试 TVM 计算图执行的接口。"
"它有助于在 TVM 运行时提供对图结构和张量值的访问。"

#: ../../../xin/docs/arch/debugger.rst:26
msgid "Debug Exchange Format"
msgstr "调试交换格式"

#: ../../../xin/docs/arch/debugger.rst:29
msgid "1. Computational Graph"
msgstr "1. 计算图"

#: ../../../xin/docs/arch/debugger.rst:30
msgid ""
"The optimized graph build by relay in json serialized format is dumped as"
" it is. This contains the whole information about the graph. The UX can "
"either use this graph directly or transform this graph to the format UX "
"can understand."
msgstr ""
"通过 json 序列化格式的 Relay 构建的优化图被丢弃了。"
"它包含了关于图的全部信息。"
"UX 可以直接使用这个图，也可以将这个图转换成 UX 可以理解的格式。"

#: ../../../xin/docs/arch/debugger.rst:35
msgid "The Graph JSON format is explained below"
msgstr "下面将解释 Graph JSON 格式"

#: ../../../xin/docs/arch/debugger.rst:37
msgid ""
"1. ``nodes`` Nodes are either placeholders or computational nodes in "
"json. The nodes are stored as a list. A node contains the below "
"information"
msgstr ""
"1. ``nodes`` 在 json 中，节点是占位符或可计算节点。节点存储为列表。节点包含以下信息"

#: ../../../xin/docs/arch/debugger.rst:41
msgid ""
"``op`` - operation type, ``null`` means it is a "
"placeholder/variable/input node and``tvm_op`` means this node can be "
"executed"
msgstr ""
"``op``：运算类型， ``null`` 意味着它是占位符/变量/输入节点，``tvm_op`` 意味着这个节点可以被执行"

#: ../../../xin/docs/arch/debugger.rst:42
msgid "``name`` - Name of the node"
msgstr "``name``：节点名字"

#: ../../../xin/docs/arch/debugger.rst:43
msgid ""
"``inputs`` - Position of the inputs for this operation, Inputs is a list "
"of tuples with (nodeid, index, version). (Optional)"
msgstr ""
"``inputs``：此运算的 inputs 位置，inputs 是包含 (nodeid, index, version) 的元组列表。(可选)"

#: ../../../xin/docs/arch/debugger.rst:44
msgid ""
"``attrs`` - Attributes of the node which contains the following "
"information"
msgstr ""
"``attrs``：包含以下信息的节点属性"

#: ../../../xin/docs/arch/debugger.rst:46
msgid "``flatten_data`` - Whether this data need to be flattened before execution"
msgstr "``flatten_data``：是否需要在执行前将数据扁平化（flattened）"

#: ../../../xin/docs/arch/debugger.rst:47
msgid ""
"``func_name`` - Fused function name, corresponds to the symbol in the lib"
" generated by relay compilation process."
msgstr ""
"``func_name``：融合函数名，对应于 Relay 编译过程生成的库中的符号。"

#: ../../../xin/docs/arch/debugger.rst:48
msgid "``num_inputs`` - Number of inputs for this node"
msgstr "``num_inputs``：此节点的 inputs 个数"

#: ../../../xin/docs/arch/debugger.rst:49
msgid "``num_outputs`` - Number of outputs this node produces"
msgstr "``num_outputs``：此节点产生的 outputs 个数"

#: ../../../xin/docs/arch/debugger.rst:51
msgid ""
"2. ``arg_nodes`` arg_nodes is a list of indices of nodes which is "
"placeholder/variable/input or constant/param to the graph."
msgstr ""
"2. ``arg_nodes`` 是节点的索引列表，它是图的 placeholder/variable/input 或 constant/param。"

#: ../../../xin/docs/arch/debugger.rst:54
msgid "3. ``heads`` heads is a list of entries as the output of the graph."
msgstr "3. ``heads`` 作为图的 output 项的列表。"

#: ../../../xin/docs/arch/debugger.rst:57
msgid ""
"4. ``node_row_ptr`` node\\_row\\_ptr stores the history of forward path, "
"so you can skip constructing the entire graph in inference tasks."
msgstr ""
"4. ``node_row_ptr`` 存储 forward 路径的历史，所以您可以跳过在推断任务中构建整个图。"

#: ../../../xin/docs/arch/debugger.rst:60
msgid ""
"5. ``attrs`` attrs can contain version numbers or similar helpful "
"information."
msgstr ""
"5. ``attrs`` 可以包含版本号或类似的有用信息。"

#: ../../../xin/docs/arch/debugger.rst:63
msgid "``storage_id`` - Memory slot id for each node in the storage layout."
msgstr "``storage_id``：存储布局中每个节点的内存 slot id。"

#: ../../../xin/docs/arch/debugger.rst:64
msgid "``dtype`` - Datatype of each node (enum value)."
msgstr "``dtype``：每个节点的数据类型 (enum 值)。"

#: ../../../xin/docs/arch/debugger.rst:65
msgid "``dltype`` - Datatype of each node in order."
msgstr "``dltype``：每个节点的数据类型按顺序排列。"

#: ../../../xin/docs/arch/debugger.rst:66
msgid "``shape`` - Shape of each node k order."
msgstr "``shape``：每个节点的形状 k 阶。"

#: ../../../xin/docs/arch/debugger.rst:67
msgid "``device_index`` - Device assignment for each entry in the graph."
msgstr "``device_index``：为图中的每个条目分配设备。"

#: ../../../xin/docs/arch/debugger.rst:69
msgid "Example of dumped graph:"
msgstr "转储图的示例："

#: ../../../xin/docs/arch/debugger.rst:109
msgid "2. Tensor dumping"
msgstr "2. Tensor 转储"

#: ../../../xin/docs/arch/debugger.rst:111
msgid ""
"The tensor received after execution is in ``tvm.ndarray`` type. All the "
"tensors will be saved as binary bytes in serialized format.  The result "
"binary bytes can be loaded by the API \"load_params\"."
msgstr ""
"执行后收到的张量在 ``tvm.ndarray`` 类型中。"
"所有的张量将以二进制字节的序列化格式保存。"
"结果二进制字节可以通过 API \"load_params\" 加载。"

#: ../../../xin/docs/arch/debugger.rst:120
msgid "Example of loading the parameters"
msgstr "加载参数的示例"

#: ../../../xin/docs/arch/debugger.rst:120
msgid "::"
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:118
msgid "with open(path_params, \"rb\") as fi:"
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:118
msgid "loaded_params = bytearray(fi.read())"
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:120
msgid "module.load_params(loaded_params)"
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:124
msgid "How to use Debugger?"
msgstr "如果使用 Debugger？"

#: ../../../xin/docs/arch/debugger.rst:126
msgid "In ``config.cmake`` set the ``USE_PROFILER`` flag to ``ON``"
msgstr "在 ``config.cmake`` 中设置 ``USE_PROFILER`` 为 ``ON``"

#: ../../../xin/docs/arch/debugger.rst:133
msgid "Do 'make' tvm, so that it will make the ``libtvm_runtime.so``"
msgstr "执行 'make' tvm，这样它就会生成 ``libtvm_runtime.so``"

#: ../../../xin/docs/arch/debugger.rst:135
msgid ""
"In frontend script file instead of ``from tvm.contrib import "
"graph_executor`` import the ``GraphModuleDebug`` ``from "
"tvm.contrib.debugger.debug_executor import GraphModuleDebug``"
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:158
msgid ""
"If network previously was exported to external library using "
"``lib.export_library(\"network.so\")``"
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:157
msgid ""
"like shared object file/dynamic linked library, the initialization of "
"debug runtime will be slightly different"
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:172
msgid ""
"The outputs are dumped to a temporary folder in ``/tmp`` folder or the "
"folder specified while creating the runtime."
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:177
msgid "Sample Output"
msgstr ""

#: ../../../xin/docs/arch/debugger.rst:179
msgid "The below is the an example output of the debugger."
msgstr ""

#~ msgid ""
#~ "In frontend script file instead of "
#~ "``from tvm.contrib import graph_executor`` "
#~ "import the ``debug_executor`` ``from "
#~ "tvm.contrib.debugger import debug_executor as "
#~ "graph_executor``"
#~ msgstr ""

#~ msgid ""
#~ "If network previously was exported to"
#~ " external libray using "
#~ "``lib.export_library(\"network.so\")``"
#~ msgstr ""

